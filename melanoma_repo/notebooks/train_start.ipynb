{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchtoolbox.transform as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from pipelinex import HatchDict\n",
    "from PIL import ImageEnhance, Image\n",
    "\n",
    "# from kedro import cata\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/kedro/framework/context/context.py:538: UserWarning: Credentials not found in your Kedro project config.\n",
      "No files found in ['/home/jupyter/kaggle/melanoma_repo/conf/base', '/home/jupyter/kaggle/melanoma_repo/conf/local'] matching the glob pattern(s): ['credentials*', 'credentials*/**', '**/credentials*']\n",
      "  str(exc)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from kedro.framework.context import load_context\n",
    "\n",
    "current_dir = Path.cwd()  # this points to 'notebooks/' folder\n",
    "proj_path = current_dir.parent  # point back to the root of the project\n",
    "context = load_context(proj_path)\n",
    "catalog = context.catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-09 06:51:35,790 - kedro.io.data_catalog - INFO - Loading data from `train` (CSVDataSet)...\n",
      "2020-07-09 06:51:36,098 - kedro.io.data_catalog - INFO - Loading data from `test` (CSVDataSet)...\n"
     ]
    }
   ],
   "source": [
    "train_df=catalog.load(\"train\")\n",
    "test_df= catalog.load(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ISIC_0149568</td>\n",
       "      <td>IP_0962375</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>ISIC_0188432</td>\n",
       "      <td>IP_0135517</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>ISIC_0207268</td>\n",
       "      <td>IP_7735373</td>\n",
       "      <td>male</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>ISIC_0232101</td>\n",
       "      <td>IP_8349964</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>ISIC_0247330</td>\n",
       "      <td>IP_3232631</td>\n",
       "      <td>female</td>\n",
       "      <td>65.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32969</th>\n",
       "      <td>ISIC_9955163</td>\n",
       "      <td>IP_7507212</td>\n",
       "      <td>male</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33000</th>\n",
       "      <td>ISIC_9963177</td>\n",
       "      <td>IP_1165806</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33014</th>\n",
       "      <td>ISIC_9967383</td>\n",
       "      <td>IP_7887363</td>\n",
       "      <td>male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33050</th>\n",
       "      <td>ISIC_9978107</td>\n",
       "      <td>IP_2860540</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33117</th>\n",
       "      <td>ISIC_9998682</td>\n",
       "      <td>IP_2516168</td>\n",
       "      <td>male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  patient_id     sex  age_approx  \\\n",
       "91     ISIC_0149568  IP_0962375  female        55.0   \n",
       "235    ISIC_0188432  IP_0135517  female        50.0   \n",
       "314    ISIC_0207268  IP_7735373    male        55.0   \n",
       "399    ISIC_0232101  IP_8349964    male        65.0   \n",
       "459    ISIC_0247330  IP_3232631  female        65.0   \n",
       "...             ...         ...     ...         ...   \n",
       "32969  ISIC_9955163  IP_7507212    male        55.0   \n",
       "33000  ISIC_9963177  IP_1165806    male        70.0   \n",
       "33014  ISIC_9967383  IP_7887363    male        60.0   \n",
       "33050  ISIC_9978107  IP_2860540    male        65.0   \n",
       "33117  ISIC_9998682  IP_2516168    male        60.0   \n",
       "\n",
       "      anatom_site_general_challenge diagnosis benign_malignant  target  \n",
       "91                  upper extremity  melanoma        malignant       1  \n",
       "235                 upper extremity  melanoma        malignant       1  \n",
       "314                           torso  melanoma        malignant       1  \n",
       "399                           torso  melanoma        malignant       1  \n",
       "459                 lower extremity  melanoma        malignant       1  \n",
       "...                             ...       ...              ...     ...  \n",
       "32969               upper extremity  melanoma        malignant       1  \n",
       "33000                         torso  melanoma        malignant       1  \n",
       "33014               upper extremity  melanoma        malignant       1  \n",
       "33050               lower extremity  melanoma        malignant       1  \n",
       "33117                     head/neck  melanoma        malignant       1  \n",
       "\n",
       "[584 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df.target == 1)  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "# concat = pd.concat([train_df['anatom_site_general_challenge'], test_df['anatom_site_general_challenge']], ignore_index=True)\n",
    "import gc\n",
    "\n",
    "\n",
    "def get_segment_age(age_approx):\n",
    "    \"\"\"\n",
    "    segment は\n",
    "    0~10\n",
    "    15~55\n",
    "    60~85\n",
    "    90\n",
    "    に分ける\n",
    "    \"\"\"\n",
    "    # 冗長的。直したい\n",
    "    feature_list=[\"age_0_10\",\n",
    "                  \"age_15_55\",\n",
    "                  \"age_60_85\",\n",
    "                  \"age_90_max\"]\n",
    "    _df =pd.DataFrame(0, index=np.arange(len(age_approx)), columns=feature_list)\n",
    "#     age_approx = df.age_approx\n",
    "    _df[\"age_0_10\"] = (age_approx < 15 )*1\n",
    "    _df[\"age_15_55\"] = ( (15<= age_approx ) &  (age_approx <60)) * 1\n",
    "    _df[\"age_60_85\"] = ( (60 <= age_approx ) &  (age_approx <90)) * 1\n",
    "    _df[\"age_90_max\"] =(90 <= age_approx) * 1\n",
    "    return _df\n",
    "                  \n",
    "    \n",
    "    \n",
    "def build_metafeatures(df):\n",
    "    dummies = pd.get_dummies(df[['sex','anatom_site_general_challenge']], dummy_na=True, dtype=np.uint8)\n",
    "    dummies = pd.concat([dummies, get_segment_age(df.age_approx)], axis=1)\n",
    "#     df.age_approx /= df.age_approx.max()\n",
    "    \n",
    "#     meta_features=pd.concat([dummies,normalized_age_approx], axis=1)\n",
    "    return pd.concat([df,dummies],axis=1), dummies.columns.tolist()\n",
    "\n",
    "def augmentation_df(df,image_folders:list ):\n",
    "    _df = df.copy()\n",
    "    image_name = _df.image_name\n",
    "#     _df = _df.drop(\"image_name\",axis=1)\n",
    "    for i, img_folder in enumerate(image_folders):\n",
    "        if i == 0:\n",
    "            df.image_name = img_folder +  df.image_name\n",
    "            print(len(df))\n",
    "            continue\n",
    "        \n",
    "        _df[\"image_name\"] =  img_folder + image_name\n",
    "        df=pd.concat([df,_df],ignore_index=True)\n",
    "        print(f\"df add {img_folder},{len(df)}\")\n",
    "    del _df,image_name\n",
    "    gc.collect()\n",
    "    \n",
    "    return df\n",
    "# train_df ,meta_features = build_metafeatures(train_df)\n",
    "# _train_df = augmentation_df(_train_df,[\"/home/jupyter/kaggle/melanoma_repo/data/01_raw/cropped\",\"/home/jupyter/kaggle/melanoma_repo/data/01_raw/cropped_aug\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-09 06:51:45,004 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n",
      "33126\n"
     ]
    }
   ],
   "source": [
    "_train_df,meta_features = build_metafeatures(train_df)\n",
    "_train_df= augmentation_df(_train_df,[\n",
    "    \"/home/jupyter/kaggle/melanoma_repo/data/01_raw/cropped_min/\",\n",
    "#     \"/home/jupyter/kaggle/melanoma_repo/data/01_raw/jpeg/train/\",\n",
    "    \n",
    "#                            \"/home/jupyter/kaggle/melanoma_repo/data/01_raw/cropped_aug/\"\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "# transforms 部分\n",
    "\n",
    "class Contrasten:\n",
    "    import numpy as np\n",
    "    def __init__(self,alpha:int=1):\n",
    "        self.alpha = 1 + alpha\n",
    "        \n",
    "    def __call__(self,img):\n",
    "        img_enhance = ImageEnhance.Contrast(img)\n",
    "        return np.asarray(img_enhance.enhance(self.alpha))\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(alpha={self.alpha})\"\n",
    "\n",
    "    \n",
    "    \n",
    "class Album:\n",
    "    lib = None\n",
    "    def __init__(self,lib, *args,**kwargs):\n",
    "        self.lib = lib\n",
    "#         self.lib = self.lib(*args,**kwargs)\n",
    "    def __call__(self,img):\n",
    "        return self.lib(image= img)\n",
    "        \n",
    "    \n",
    "class _Horizontal(Album):\n",
    "#     def __init(self, *args)\n",
    "    lib = A.HorizontalFlip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  PIL import Image, ImageEnhance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):  # Swish activation                                      \n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, imfolder: str, train: bool = True, transforms = None, meta_features = None, contrast=1.5):\n",
    "        \"\"\"\n",
    "        Class initialization\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with data description\n",
    "            imfolder (str): folder with images\n",
    "            train (bool): flag of whether a training dataset is being initialized or testing one\n",
    "            transforms: image transformation method to be applied\n",
    "            meta_features (list): list of features with meta information, such as sex and age\n",
    "            \n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.imfolder = imfolder\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        self.meta_features = meta_features\n",
    "        self.contrast = contrast\n",
    "        self.to_tensor = ToTensor()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        im_path = self.df.iloc[index]['image_name'] + '.jpg'\n",
    "        x=Image.open(im_path)\n",
    "        \n",
    "#         x = \n",
    "#         x = cv2.imread(im_path)\n",
    "#         x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "        meta = np.array(self.df.iloc[index][self.meta_features].values, dtype=np.float32)\n",
    "\n",
    "        if self.transforms:\n",
    "            x = self.transforms(x)\n",
    "            \n",
    "        if self.train:\n",
    "            y = self.df.iloc[index]['target']\n",
    "            \n",
    "#             y=torch.from_numpy(np.asarray(y))\n",
    "#             print(y,y.size)\n",
    "#             y =torch.unsqueeze(y,1)\n",
    "#             print(y,y.shape)\n",
    "            return (x, meta), y\n",
    "        else:\n",
    "            return (x, meta)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "class NetProto(nn.Module):\n",
    "    def __init__(self, arch, n_meta_features: int):\n",
    "        super(NetProto, self).__init__()\n",
    "        self.arch = arch\n",
    "        if 'ResNet' in str(arch.__class__):\n",
    "            self.arch.fc = nn.Linear(in_features=512, out_features=500, bias=True)\n",
    "        if 'EfficientNet' in str(arch.__class__):\n",
    "            num_ftrs = self.arch._fc.in_features\n",
    "            self.arch._fc = nn.Linear(in_features=num_ftrs, out_features=500, bias=True)\n",
    "            \n",
    "        self.meta = nn.Sequential(nn.Linear(n_meta_features, 500),\n",
    "                                  nn.BatchNorm1d(500),\n",
    "                                  Swish(),\n",
    "#                                   nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2),\n",
    "                                  nn.Linear(500, 250),  # FC layer output will have 250 features\n",
    "                                  nn.BatchNorm1d(250),\n",
    "                                  Swish(),\n",
    "#                                   nn.ReLU(),\n",
    "                                  nn.Dropout(p=0.2))\n",
    "        self.ouput = nn.Linear(500 + 250\n",
    "                               ,\n",
    "                               1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
    "        Which applies sigmoid for us when calculating a loss\n",
    "        \"\"\"\n",
    "        x, meta = inputs\n",
    "        cnn_features = self.arch(x)\n",
    "#         features = self.arch(x)\n",
    "        \n",
    "        meta_features = self.meta(meta)\n",
    "        features = torch.cat((cnn_features, meta_features), dim=1)\n",
    "    \n",
    "        output = self.ouput(features)\n",
    "        output=output.float()\n",
    "#         print(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.contrib.metrics import ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# img = cv2.imread(\"/home/jupyter/kaggle/melanoma_repo/data/01_raw/cropped/ISIC_6260086.jpg\")\n",
    "    \n",
    "# hoge = _Horizontal(p=1)\n",
    "# hoge(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=Image.open('/kaggle/input/melanoma-external-malignant-256/train/train/ISIC_6260086.jpg',) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=Image.open(\"/home/jupyter/kaggle/melanoma_repo/data/01_raw/cropped/ISIC_6260086.jpg\")\n",
    "# img2=Image.open(\"/home/jupyter/kaggle/melanoma_repo/data/01_raw/external_malignant/train/ISIC_6260086.jpg\")\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     Contrasten(alpha=.5),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "\n",
    "# hoge = img.copy()\n",
    "# # print(train_transform)\n",
    "# hoge=Contrasten(alpha=.5)(hoge)\n",
    "# hoge=transforms.ToTensor()(hoge)\n",
    "# # hoge=transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])(hoge)\n",
    "\n",
    "# hoge=hoge.to(\"cpu\").detach().numpy().copy()\n",
    "# print(hoge)\n",
    "# Image.fromarray(hoge)\n",
    "\n",
    "# hoge.mean()\n",
    "# plt.imshow(hoge)\n",
    "# for call in train_transform:\n",
    "#     hoge=call(hoge)\n",
    "\n",
    "    \n",
    "# hoge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ColorJitter\n",
    "# color_jitter = ColorJitter(saturation=0.4,contrast=0.4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Engine\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss,ConfusionMatrix\n",
    "from ignite.contrib.metrics import ROC_AUC\n",
    "\n",
    "def get_data_loaders(train_batch_size,trian_idx,val_idx, val_batch_size,imfolder=\"/home/jupyter/kaggle/melanoma_repo/data/01_raw/cropped_aug/\"):\n",
    "    \"\"\"\n",
    "    data_loader を取得する\n",
    "    \n",
    "    \"\"\"\n",
    "    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "    Contrasten(alpha=.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        Contrasten(alpha=.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = MelanomaDataset(df=train_df.iloc[train_idx].reset_index(drop=True), \n",
    "                            imfolder=imfolder, \n",
    "                            train=True, \n",
    "                            transforms=train_transform,\n",
    "                            meta_features=meta_features)\n",
    "\n",
    "    val_dataset = MelanomaDataset(df=train_df.iloc[val_idx].reset_index(drop=True), \n",
    "                            imfolder=imfolder, \n",
    "                            train=True, \n",
    "                            transforms=train_transform,\n",
    "                            meta_features=meta_features)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, \n",
    "                   batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_dataset, \n",
    "                   batch_size=val_batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss,ConfusionMatrix\n",
    "from ignite.contrib.metrics import ROC_AUC\n",
    "from datetime import datetime\n",
    "\n",
    "def score_function(engine):\n",
    "    \"\"\"\n",
    "    ignite.handlers.EarlyStopping では指定スコアが上がると改善したと判定する。\n",
    "    \"\"\"\n",
    "    val_loss = engine.state.metrics['roc_auc']\n",
    "    return val_loss\n",
    "\n",
    "def write_metrics(metrics, writer, mode: str, epoch: int):\n",
    "    \"\"\"print metrics & write metrics to log\"\"\"\n",
    "    roc_auc = metrics['roc_auc']\n",
    "    loss = metrics['loss']\n",
    "    print(f\"{mode} Results - Epoch: {epoch}  \"\n",
    "          f\"Avg roc_auc: {roc_auc:.2f} Avg loss: {loss:.2f}\")\n",
    "    writer.add_scalar(f\"{mode}/roc_auc\", roc_auc, epoch)\n",
    "    writer.add_scalar(f\"{mode}/loss\", loss, epoch)\n",
    "\n",
    "    \n",
    "def _train(epochs,\n",
    "          model,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          criterion,\n",
    "          optimizer, \n",
    "          writer,\n",
    "          device:str,\n",
    "          log_interval,\n",
    "          patience=5,\n",
    "          metrics={}\n",
    "         ):\n",
    "    \n",
    "    \n",
    "#     def update_model(engine, batch):\n",
    "#         inputs, targets = batch\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, targets.unsqueeze(1))\n",
    "#         optimizer.step()\n",
    "#         return loss.item()\n",
    "    from ignite.utils import convert_tensor\n",
    "    def normalize_batch(batch, device = None, non_blocking: bool = False):\n",
    "        x, y =batch\n",
    "        return (convert_tensor(x, device=device, non_blocking=non_blocking),\n",
    "                \n",
    "        convert_tensor(y, device=device, non_blocking=non_blocking).unsqueeze(1).float(),\n",
    "        )\n",
    "    \n",
    "    \n",
    "    trainer = create_supervised_trainer(model,\n",
    "                                        optimizer,\n",
    "                                       criterion,\n",
    "                                       device,\n",
    "                                       prepare_batch=normalize_batch)\n",
    "    evaluator = create_supervised_evaluator(model,\n",
    "                                            metrics=metrics,\n",
    "                                            device=device\n",
    "    )\n",
    "    # TODOaccurate をいれる\n",
    "    @trainer.on(Events.ITERATION_COMPLETED)\n",
    "    def log_training_loss(engine):\n",
    "        i = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "        if i % log_interval == 0:\n",
    "            print(f\"Epoch[{engine.state.epoch}] Iteration[{i}/{len(train_loader)}] \"\n",
    "                  f\"Loss: {engine.state.output:.4f}\")\n",
    "            # engine.state.output は criterion(model(input)) を表す？\n",
    "            writer.add_scalar(\"training/loss\", engine.state.output,\n",
    "                              engine.state.iteration)\n",
    "\n",
    "#     @trainer.on(Events.EPOCH_COMPLETED)\n",
    "#     def log_training_results(engine):\n",
    "#         evaluator.run(valid_loader)\n",
    "#         metrics = evaluatorevaluator.state.metrics\n",
    "#         write_metrics(metrics, writer, 'training', engine.state.epoch)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        evaluator.run(valid_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        write_metrics(metrics, writer, 'validation', engine.state.epoch)    \n",
    "    \n",
    "\n",
    "    \n",
    "    # # Checkpoint setting\n",
    "    # ./checkpoints/sample_mymodel_{step_number}\n",
    "    # n_saved 個までパラメータを保持する\n",
    "    handler = ModelCheckpoint(dirname='/home/jupyter/kaggle/melanoma_repo/data/06_models/checkpoints/start_'+datetime.now().strftime(\"%Y%m%d_%H%M\"), filename_prefix='start',\n",
    "                               n_saved=3, create_dir=True)\n",
    "    trainer.add_event_handler(Events.EPOCH_COMPLETED, handler, {'mymodel': model})\n",
    "\n",
    "    # # Early stopping\n",
    "    handler = EarlyStopping(patience=patience, score_function=score_function, trainer=trainer)\n",
    "    # Note: the handler is attached to an *Evaluator* (runs one epoch on validation dataset)\n",
    "    evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "\n",
    "    # kick everything off\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "#         y = one_hot(target, input.size(-1))\n",
    "\n",
    "        logit = torch.sigmoid(inputs)\n",
    "        logit = logit.clamp(self.eps, 1. - self.eps)\n",
    "\n",
    "        loss = -1 * target * torch.log(logit) # cross entropy\n",
    "        loss = loss * (1 - logit) ** self.gamma # focal loss\n",
    "\n",
    "        return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class _RandomSizedCrop(Album):\n",
    "#     lib = A.RandomSizedCrop\n",
    "# class _HorizontalFlip(Album):\n",
    "#     lib  =A.HorizontalFlip\n",
    "# class _VerticalFlip(Album):\n",
    "#     lib = A.VerticalFlip\n",
    "# class _GaussianBlur(Album):\n",
    "#     lib = A.GaussianBlur\n",
    "# class _Cutout(Album):\n",
    "#     lib = A.Cutout\n",
    "\n",
    "\n",
    "#               A.RandomSizedCrop(min_max_height=(int(resolution*0.7), input_res),\n",
    "#                               height=resolution, width=resolution, p=1.0),\n",
    "#             A.HorizontalFlip(p=0.5),\n",
    "#             A.(p=0.5),\n",
    "#             A.GaussianBlur(p=0.3),\n",
    "        \n",
    "#             A.Cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedHairAugmentation:\n",
    "    def __init__(self, hairs: int = 4, hairs_folder: str = \"/home/jupyter/kaggle/melanoma_repo/data/01_raw/hair_imgs\"):\n",
    "        self.hairs = hairs\n",
    "        self.hairs_folder = hairs_folder\n",
    "        self.hair_images = [im for im in os.listdir(self.hairs_folder) if 'png' in im]\n",
    "    def __call__(self, img):\n",
    "        n_hairs = random.randint(0, self.hairs)\n",
    "\n",
    "        if not n_hairs:\n",
    "            return img\n",
    "\n",
    "        height, width, _ = img.shape  # target image width and height\n",
    "        img.flags.writeable = True\n",
    "#         print(img.flags.writeable)\n",
    "        for _ in range(n_hairs):\n",
    "            hair = cv2.imread(os.path.join(self.hairs_folder, random.choice(self.hair_images)))\n",
    "            hair = cv2.flip(hair, random.choice([-1, 0, 1]))\n",
    "            hair = cv2.rotate(hair, random.choice([0, 1, 2]))\n",
    "\n",
    "            h_height, h_width, _ = hair.shape  # hair image width and height\n",
    "            roi_ho = random.randint(0, img.shape[0] - hair.shape[0])\n",
    "            roi_wo = random.randint(0, img.shape[1] - hair.shape[1])\n",
    "            roi = img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width]\n",
    "\n",
    "            img2gray = cv2.cvtColor(hair, cv2.COLOR_BGR2GRAY)\n",
    "            ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "            mask_inv = cv2.bitwise_not(mask)\n",
    "            img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "            hair_fg = cv2.bitwise_and(hair, hair, mask=mask)\n",
    "\n",
    "            dst = cv2.add(img_bg, hair_fg)\n",
    "            \n",
    "            img[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width] = dst\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hoge = AdvancedHairAugmentation(6)\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "node"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "# 訓練メイン処理\n",
    "from tensorboardX import SummaryWriter\n",
    "from ignite.handlers import ModelCheckpoint, Checkpoint,EarlyStopping\n",
    "log_writer = SummaryWriter(\"/home/jupyter/kaggle/melanoma_repo/logs\")\n",
    "\n",
    "LOG_INTERVAL = 10\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = FocalLoss(2.)\n",
    "\n",
    "metrics = {\n",
    "    \"confusion_matrix\": ConfusionMatrix(1),\n",
    "    \"roc_auc\": ROC_AUC(),\n",
    "    \"loss\":Loss(criterion)\n",
    "}\n",
    "\n",
    "#     model = Net(arch=arch, n_meta_features=128)  # TODO これはかくCVごとに初期化する\n",
    "\n",
    "\n",
    "epochs = 20  # Number of epochs to run　TODO param か\n",
    "model_path = 'model.pth'  # Path and filename to save model to\n",
    "es_espatience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "oof = np.zeros((len(train_df), 1))  # Out Of Fold predictions\n",
    "# preds = torch.zeros((len(test), 1), dtype=torch.float32, device=device) ra # Predictions for test test\n",
    "resolution = 456  # orignal res for B5\n",
    "input_res  = 512\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            Contrasten(alpha=.6),\n",
    "#             AdvancedHairAugmentation(6),\n",
    "#             transforms.ColorJitter(brightness=.4,contrast=0.5,saturation=.4),\n",
    "    \n",
    "    \n",
    "#             Album(A.RandomSizedCrop(min_max_height=(int(resolution*0.7), input_res),\n",
    "#                               height=resolution, width=resolution, p=1.0),),\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "#             A.VerticalFlip(p=0.5),\n",
    "# A.GaussianBlur(p=0.3),\n",
    "# A.Cutout(num_holes=8, max_h_size=resolution//8, max_w_size=resolution//8, fill_value=0, p=0.3),\n",
    "#     ToTensorV2(),\n",
    "#             Album(A.HorizontalFlip(p=0.5),),\n",
    "#             Album(A.VerticalFlip(p=0.5),),\n",
    "#             Album(A.GaussianBlur(p=0.3),),\n",
    "#             Album(A.Cutout(num_holes=8, max_h_size=resolution//8, max_w_size=resolution//8, fill_value=0, p=0.3),),\n",
    "     \n",
    "    \n",
    "    \n",
    "\n",
    "transforms.ToTensor(),\n",
    "# transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "arch = EfficientNet.from_pretrained('efficientnet-b5') # TODO param化\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=999, shuffle=True)\n",
    "# skf = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_CHECKPOINT_PATH =\"/home/jupyter/kaggle/melanoma_repo/data/06_models/checkpoints/start_20200709_0653/start_mymodel_1656.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "node"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 1 ====================\n",
      "2020-07-09 06:53:19,265 - ignite.engine.engine.Engine - INFO - Engine run starting with max_epochs=20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/efficientnet_pytorch/utils.py:45: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n",
      "  i = ctx.saved_variables[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[10/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[20/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[30/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[40/414] Loss: 0.0033\n",
      "Epoch[1] Iteration[50/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[60/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[70/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[80/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[90/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[100/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[110/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[120/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[130/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[140/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[150/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[160/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[170/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[180/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[190/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[200/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[210/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[220/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[230/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[240/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[250/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[260/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[270/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[280/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[290/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[300/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[310/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[320/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[330/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[340/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[350/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[360/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[370/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[380/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[390/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[400/414] Loss: 0.0000\n",
      "Epoch[1] Iteration[410/414] Loss: 0.0000\n",
      "2020-07-09 07:03:37,093 - ignite.engine.engine.Engine - INFO - Engine run starting with max_epochs=1.\n",
      "2020-07-09 07:05:38,556 - ignite.engine.engine.Engine - INFO - Epoch[1] Complete. Time taken: 00:02:01\n",
      "2020-07-09 07:05:38,558 - ignite.engine.engine.Engine - INFO - Engine run complete. Time taken: 00:02:01\n",
      "validation Results - Epoch: 1  Avg roc_auc: 0.73 Avg loss: 0.01\n",
      "2020-07-09 07:05:38,910 - ignite.engine.engine.Engine - INFO - Epoch[1] Complete. Time taken: 00:10:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/efficientnet_pytorch/utils.py:45: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n",
      "  i = ctx.saved_variables[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2] Iteration[10/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[20/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[30/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[40/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[50/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[60/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[70/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[80/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[90/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[100/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[110/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[120/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[130/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[140/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[150/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[160/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[170/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[180/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[190/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[200/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[210/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[220/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[230/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[240/414] Loss: 2.9384\n",
      "Epoch[2] Iteration[250/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[260/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[270/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[280/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[290/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[300/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[310/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[320/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[330/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[340/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[350/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[360/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[370/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[380/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[390/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[400/414] Loss: 0.0000\n",
      "Epoch[2] Iteration[410/414] Loss: 0.0000\n",
      "2020-07-09 07:15:45,673 - ignite.engine.engine.Engine - INFO - Engine run starting with max_epochs=1.\n"
     ]
    }
   ],
   "source": [
    "# We stratify by target value, thus, according to sklearn StratifiedKFold documentation\n",
    "# We can fill `X` with zeroes of corresponding length to use it as a placeholder\n",
    "# since we only need `y` to stratify the data\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target']), 1):\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(_train_df)), y=_train_df['target'], groups=_train_df['patient_id'].tolist()), 1):\n",
    "    print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "    \n",
    "    best_val = None  # Best validation score within this fold\n",
    "    patience = es_espatience # Current patience counter\n",
    "    \n",
    "    model = NetProto(arch=arch, n_meta_features=len(meta_features))  # New model for each fold\n",
    "    model = model.to(device)\n",
    "    model=torch.nn.DataParallel(model)\n",
    "    if fold == 0 && MODEL_CHECKPOINT_PATH is not None:\n",
    "        model.load_state_dict(torch.load(MODEL_CHECKPOINT_PATH))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 可変できるなら可変で\n",
    "#     optim = torch.optim.Adam(model.parameters(), lr=0.001)# TODO param化\n",
    "    scheduler = ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=1, verbose=True, factor=0.2)\n",
    "    criterion = nn.BCEWithLogitsLoss()#FocalLoss(2.)\n",
    "    \n",
    "    train = MelanomaDataset(df=_train_df.iloc[train_idx].reset_index(drop=True), \n",
    "                            imfolder='/home/jupyter/kaggle/melanoma_repo/data/01_raw/cropped_min/', \n",
    "                            train=True, \n",
    "                            transforms=transform,\n",
    "                            meta_features=meta_features)\n",
    "    val = MelanomaDataset(df=_train_df.iloc[val_idx].reset_index(drop=True), \n",
    "                            imfolder='/home/jupyter/kaggle/melanoma_repo/data/01_raw/cropped_min/', \n",
    "                            train=True, \n",
    "                            transforms=transform,\n",
    "                            meta_features=meta_features)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train, batch_size=64, shuffle=True, num_workers=4,drop_last=True)\n",
    "    val_loader = DataLoader(dataset=val, batch_size=16, shuffle=False, num_workers=4)\n",
    "    _train(epochs,\n",
    "          model,\n",
    "          train_loader,\n",
    "          val_loader,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          log_writer,\n",
    "          device,\n",
    "          LOG_INTERVAL,\n",
    "          patience,\n",
    "          metrics\n",
    "          \n",
    "     )\n",
    "#     test_loader = DataLoader(dataset=test, batch_size=16, shuffle=False, num_workers=2)\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "#         start_time = time.time()\n",
    "#         correct = 0\n",
    "#         epoch_loss = 0\n",
    "#         model.train()\n",
    "        \n",
    "#         for x, y in train_loader:\n",
    "#             x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n",
    "#             x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n",
    "#             y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "#             optim.zero_grad()\n",
    "#             z = model(x)\n",
    "#             loss = criterion(z, y.unsqueeze(1))\n",
    "#             loss.backward()\n",
    "#             optim.step()\n",
    "#             pred = torch.round(torch.sigmoid(z))  # round off sigmoid to obtain predictions\n",
    "#             correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()  # tracking number of correctly predicted samples\n",
    "#             epoch_loss += loss.item()\n",
    "#         train_acc = correct / len(train_idx)\n",
    "\n",
    "#         model.eval()  # switch model to the evaluation mode\n",
    "#         val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "#         with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
    "#             # Predicting on validation set\n",
    "#             for j, (x_val, y_val) in enumerate(val_loader):\n",
    "#                 x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "#                 x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "#                 y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "#                 z_val = model(x_val)\n",
    "#                 val_pred = torch.sigmoid(z_val)\n",
    "#                 val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "#             val_acc = accuracy_score(train_df.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
    "#             val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, val_preds.cpu())\n",
    "            \n",
    "#             print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
    "#             epoch + 1, \n",
    "#             epoch_loss, \n",
    "#             train_acc, \n",
    "#             val_acc, \n",
    "#             val_roc, \n",
    "#             str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
    "            \n",
    "#             scheduler.step(val_roc)\n",
    "#             # During the first iteration (first epoch) best validation is set to None\n",
    "#             if not best_val:\n",
    "#                 best_val = val_roc  # So any validation roc_auc we have is the best one for now\n",
    "#                 torch.save(model, model_path)  # Saving the model\n",
    "#                 continue\n",
    "                \n",
    "#             if val_roc >= best_val:\n",
    "#                 best_val = val_roc\n",
    "#                 patience = es_patience  # Resetting patience since we have new best validation accuracy\n",
    "#                 torch.save(model, model_path)  # Saving current best model\n",
    "#             else:\n",
    "#                 patience -= 1\n",
    "#                 if patience == 0:\n",
    "#                     print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
    "#                     break\n",
    "                \n",
    "#     model = torch.load(model_path)  # Loading best model of this fold\n",
    "#     model.eval()  # switch model to the evaluation mode\n",
    "#     val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         # Predicting on validation set once again to obtain data for OOF\n",
    "#         for j, (x_val, y_val) in enumerate(val_loader):\n",
    "#             x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "#             x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "#             y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "#             z_val = model(x_val)\n",
    "#             val_pred = torch.sigmoid(z_val)\n",
    "#             val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n",
    "#         oof[val_idx] = val_preds.cpu().numpy()\n",
    "        \n",
    "#         # Predicting on test set\n",
    "#         for _ in range(TTA):\n",
    "#             for i, x_test in enumerate(test_loader):\n",
    "#                 x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n",
    "#                 x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n",
    "#                 z_test = model(x_test)\n",
    "#                 z_test = torch.sigmoid(z_test)\n",
    "#                 preds[i*x_test[0].shape[0]:i*x_test[0].shape[0] + x_test[0].shape[0]] += z_test\n",
    "#         preds /= TTA\n",
    "        \n",
    "    del train, val, train_loader, val_loader, x_val, y_val\n",
    "    gc.collect()\n",
    "    \n",
    "# preds /= skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
