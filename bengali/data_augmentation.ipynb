{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecordを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#sklearns \n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# keras modules \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n",
    "from keras.optimizers import Adam, Nadam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D, GlobalMaxPooling2D, concatenate\n",
    "from keras.layers import (MaxPooling2D, Input, Average, Activation, MaxPool2D,\n",
    "                          Flatten, LeakyReLU, BatchNormalization)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras import utils as np_utils\n",
    "from keras.callbacks import (Callback, ModelCheckpoint,\n",
    "                                        LearningRateScheduler,EarlyStopping, \n",
    "                                        ReduceLROnPlateau,CSVLogger)\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2020\n",
    "batch_size = 12 \n",
    "dim = (128, 128)\n",
    "SIZE = 128\n",
    "stats = (0.0692, 0.2051)\n",
    "HEIGHT = 137 \n",
    "WIDTH = 236\n",
    "NEW_HEIGHT = HEIGHT * .7\n",
    "NEW_WIDTH = WIDTH * .7\n",
    "def seed_all(SEED):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    \n",
    "# seed all\n",
    "seed_all(SEED)\n",
    "\n",
    "# # load files\n",
    "# im_path = '../input/grapheme-imgs-128x128/'\n",
    "# train = pd.read_csv('../input/bengaliai-cv19/train.csv')\n",
    "# test = pd.read_csv('../input/bengaliai-cv19/test.csv')\n",
    "\n",
    "# train = train.sample(frac=1).reset_index(drop=True) # shuffling \n",
    "# train['filename'] = train.image_id.apply(lambda filename: im_path + filename + '.png')\n",
    "\n",
    "# # top 5 samples\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Mask\n",
    "# code takesn from https://www.kaggle.com/haqishen/gridmask\n",
    "\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, ImageOnlyTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "\n",
    "class GridMask(DualTransform):\n",
    "    \"\"\"GridMask augmentation for image classification and object detection.\n",
    "\n",
    "    Args:\n",
    "        num_grid (int): number of grid in a row or column.\n",
    "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
    "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
    "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
    "        mode (int):\n",
    "            0 - cropout a quarter of the square of each grid (left top)\n",
    "            1 - reserve a quarter of the square of each grid (left top)\n",
    "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
    "\n",
    "    Targets:\n",
    "        image, mask\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "\n",
    "    Reference:\n",
    "    |  https://arxiv.org/abs/2001.04086\n",
    "    |  https://github.com/akuxcw/GridMask\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "\n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        return image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUGmiX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmix : https://github.com/google-research/augmix\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "\n",
    "def int_parameter(level, maxval):\n",
    "    \"\"\"Helper function to scale `val` between 0 and maxval .\n",
    "    Args:\n",
    "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
    "    maxval: Maximum value that the operation can have. This will be scaled to\n",
    "      level/PARAMETER_MAX.\n",
    "    Returns:\n",
    "    An int that results from scaling `maxval` according to `level`.\n",
    "    \"\"\"\n",
    "    return int(level * maxval / 10)\n",
    "\n",
    "\n",
    "def float_parameter(level, maxval):\n",
    "    \"\"\"Helper function to scale `val` between 0 and maxval.\n",
    "    Args:\n",
    "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
    "    maxval: Maximum value that the operation can have. This will be scaled to\n",
    "      level/PARAMETER_MAX.\n",
    "    Returns:\n",
    "    A float that results from scaling `maxval` according to `level`.\n",
    "    \"\"\"\n",
    "    return float(level) * maxval / 10.\n",
    "\n",
    "def sample_level(n):\n",
    "    return np.random.uniform(low=0.1, high=n)\n",
    "\n",
    "def autocontrast(pil_img, _):\n",
    "    return ImageOps.autocontrast(pil_img)\n",
    "\n",
    "def equalize(pil_img, _):\n",
    "    return ImageOps.equalize(pil_img)\n",
    "\n",
    "def posterize(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), 4)\n",
    "    return ImageOps.posterize(pil_img, 4 - level)\n",
    "\n",
    "def rotate(pil_img, level):\n",
    "    degrees = int_parameter(sample_level(level), 30)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        degrees = -degrees\n",
    "    return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
    "\n",
    "def solarize(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), 256)\n",
    "    return ImageOps.solarize(pil_img, 256 - level)\n",
    "\n",
    "def shear_x(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 0.3)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((SIZE, SIZE),\n",
    "                           Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "def shear_y(pil_img, level):\n",
    "    level = float_parameter(sample_level(level), 0.3)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((SIZE, SIZE),\n",
    "                           Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "def translate_x(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), SIZE / 3)\n",
    "    if np.random.random() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((SIZE, SIZE),\n",
    "                           Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "def translate_y(pil_img, level):\n",
    "    level = int_parameter(sample_level(level), SIZE / 3)\n",
    "    if np.random.random() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform((SIZE, SIZE),\n",
    "                           Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
    "                           resample=Image.BILINEAR)\n",
    "\n",
    "augmentations = [\n",
    "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
    "    translate_x, translate_y\n",
    "]\n",
    "\n",
    "# taken from https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "MEAN = [ 0.06922848809290576,  0.06922848809290576,  0.06922848809290576]\n",
    "STD = [ 0.20515700083327537,  0.20515700083327537,  0.20515700083327537]\n",
    "\n",
    "def normalize(image):\n",
    "    \"\"\"Normalize input image channel-wise to zero mean and unit variance.\"\"\"\n",
    "    image = image.transpose(2, 0, 1)  # Switch to channel-first\n",
    "    mean, std = np.array(MEAN), np.array(STD)\n",
    "    image = (image - mean[:, None, None]) / std[:, None, None]\n",
    "    return image.transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "def apply_op(image, op, severity):\n",
    "    image = np.clip(image * 255., 0, 255).astype(np.uint8)\n",
    "    pil_img = Image.fromarray(image)  # Convert to PIL.Image\n",
    "    pil_img = op(pil_img, severity)\n",
    "    return np.asarray(pil_img) / 255.\n",
    "\n",
    "\n",
    "def augment_and_mix(image, severity=1, width=3, depth=1, alpha=1.):\n",
    "    \"\"\"Perform AugMix augmentations and compute mixture.\n",
    "    Args:\n",
    "    image: Raw input image as float32 np.ndarray of shape (h, w, c)\n",
    "    severity: Severity of underlying augmentation operators (between 1 to 10).\n",
    "    width: Width of augmentation chain\n",
    "    depth: Depth of augmentation chain. -1 enables stochastic depth uniformly\n",
    "      from [1, 3]\n",
    "    alpha: Probability coefficient for Beta and Dirichlet distributions.\n",
    "    Returns:\n",
    "    mixed: Augmented and mixed image.\n",
    "  \"\"\"\n",
    "    ws = np.float32(\n",
    "      np.random.dirichlet([alpha] * width))\n",
    "    m = np.float32(np.random.beta(alpha, alpha))\n",
    "\n",
    "    mix = np.zeros_like(image)\n",
    "    for i in range(width):\n",
    "        image_aug = image.copy()\n",
    "        depth = depth if depth > 0 else np.random.randint(1, 4)\n",
    "        \n",
    "        for _ in range(depth):\n",
    "            op = np.random.choice(augmentations)\n",
    "            image_aug = apply_op(image_aug, op, severity)\n",
    "        mix = np.add(mix, ws[i] * normalize(image_aug), out=mix, \n",
    "                     casting=\"unsafe\")\n",
    "\n",
    "    mixed = (1 - m) * normalize(image) + m * mix\n",
    "    return mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grapheme Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphemeGenerator(Sequence):\n",
    "    def __init__(self, data, batch_size, dim, shuffle=True, transform=None):\n",
    "        self._data = data\n",
    "        self._label_1 = pd.get_dummies(self._data['grapheme_root'], \n",
    "                                       columns = ['grapheme_root'])\n",
    "        self._label_2 = pd.get_dummies(self._data['vowel_diacritic'], \n",
    "                                       columns = ['vowel_diacritic'])\n",
    "        self._label_3 = pd.get_dummies(self._data['consonant_diacritic'], \n",
    "                                       columns = ['consonant_diacritic'])\n",
    "        self._list_idx = data.index.values\n",
    "        self._batch_size = batch_size\n",
    "        self._dim = dim\n",
    "        self._shuffle = shuffle\n",
    "        self.transform = transform\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self._data)/self._batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_idx = self._indices[index*self._batch_size:(index+1)*self._batch_size]\n",
    "        _idx = [self._list_idx[k] for k in batch_idx]\n",
    "\n",
    "        Data     = np.empty((self._batch_size, *self._dim, 1))\n",
    "        Target_1 = np.empty((self._batch_size, 168), dtype = int)\n",
    "        Target_2 = np.empty((self._batch_size, 11 ), dtype = int)\n",
    "        Target_3 = np.empty((self._batch_size,  7 ), dtype = int)\n",
    "        \n",
    "        for i, k in enumerate(_idx):\n",
    "            # load the image file using cv2\n",
    "            image = cv2.imread(im_path + self._data['image_id'][k] + '.png')\n",
    "            image = cv2.resize(image,  self._dim) \n",
    "            if self.transform is not None:\n",
    "                if np.random.rand() > 0.7:\n",
    "                    # albumentation : grid mask\n",
    "                    res = self.transform(image=image)\n",
    "                    image = res['image']\n",
    "                else:\n",
    "                    # augmix augmentation\n",
    "                    image = augment_and_mix(image)\n",
    "            \n",
    "            # scaling \n",
    "            image = (image.astype(np.float32)/255.0 - stats[0])/stats[1]\n",
    "            \n",
    "            # gray scaling \n",
    "            gray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114]) \n",
    "            image = gray(image)  \n",
    "            \n",
    "            # expand the axises \n",
    "            image = image[:, :, np.newaxis]\n",
    "            Data[i,:, :, :] =  image\n",
    "        \n",
    "            Target_1[i,:] = self._label_1.loc[k, :].values\n",
    "            Target_2[i,:] = self._label_2.loc[k, :].values\n",
    "            Target_3[i,:] = self._label_3.loc[k, :].values\n",
    "            \n",
    "        return Data, [Target_1, Target_2, Target_3]\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self._indices = np.arange(len(self._list_idx))\n",
    "        if self._shuffle:\n",
    "            np.random.shuffle(self._indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO TFRecord作る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グレースケール化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "165\n"
     ]
    }
   ],
   "source": [
    "# Custom \n",
    "# from preprocessing import generate_images, resize_image\n",
    "# from model import create_model\n",
    "# from utils import plot_summaries\n",
    "\n",
    "# Seeds\n",
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "\n",
    "# Input Dir\n",
    "DATA_DIR = './input/'\n",
    "TRAIN_DIR = \"./mixup_img_dir/\"#'./trained/'\n",
    "\n",
    "# Constants\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "SCALE_FACTOR = 0.70\n",
    "HEIGHT_NEW = int(HEIGHT * SCALE_FACTOR)\n",
    "WIDTH_NEW = int(WIDTH * SCALE_FACTOR)\n",
    "RUN_NAME = 'Train1_'\n",
    "PLOT_NAME1 = 'Train1_LossAndAccuracy.png'\n",
    "PLOT_NAME2 = 'Train1_Recall.png'\n",
    "\n",
    "BATCH_SIZE = 56\n",
    "CHANNELS = 3\n",
    "EPOCHS = 80\n",
    "TEST_SIZE = 1./6\n",
    "\n",
    "# Image Size Summary\n",
    "print(HEIGHT_NEW)\n",
    "print(WIDTH_NEW)\n",
    "\n",
    "# Generate Image (Has to be done only one time .. or again when changing SCALE_FACTOR)\n",
    "GENERATE_IMAGES = False\n",
    "if GENERATE_IMAGES:\n",
    "    generate_images(DATA_DIR, TRAIN_DIR, WIDTH, HEIGHT, WIDTH_NEW, HEIGHT_NEW)\n",
    "\n",
    "# Prepare Train Labels (Y)\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "tgt_cols = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\n",
    "desc_df = train_df[tgt_cols].astype('str').describe()\n",
    "types = desc_df.loc['unique',:]\n",
    "X_train = train_df['image_id'].values\n",
    "train_df = train_df[tgt_cols].astype('uint8')\n",
    "for col in tgt_cols:\n",
    "    train_df[col] = train_df[col].map('{:03}'.format)\n",
    "# Y_train = pd.get_dummies(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH_NEW =165\n",
    "HEIGHT_NEW = 95\n",
    "TRAIN_DIR=\"./mixup_img_dir/\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "def _read(path):\n",
    "    img = cv2.imread(path)    \n",
    "#     img = Image.open(path)\n",
    "#     img = np.array(img.convert(\"L\"))\n",
    "    return img\n",
    "def resize_image_adhoc(img):\n",
    "    # Invert\n",
    "#     img = 255 - img\n",
    "\n",
    "    # Normalize\n",
    "    img = (img * (255.0 / img.max())).astype(np.uint8)\n",
    "\n",
    "    # Reshape\n",
    "#     img = img.reshape(org_height, org_width)\n",
    "#     image_resized = cv2.resize(img, (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "#     img_bgrL = cv2.LUT(img_bgr, gamma22LUT)\n",
    "#     img_grayL = cv2.cvtColor(img_bgrL, cv2.COLOR_BGR2GRAY)\n",
    "#     img_gray = pow(img_grayL, 1.0/2.2) * 255\n",
    "\n",
    "#     img, _ = cv2.decolor(img)\n",
    "    return img\n",
    "\n",
    "def resize_and_save_image_adhoc(train_dir, img, image_id):\n",
    "    # Resize Image\n",
    "    image_resized = resize_image_adhoc(img,)\n",
    "\n",
    "    # Save Image\n",
    "    cv2.imwrite(train_dir + str(image_id) + '.png', image_resized)\n",
    "    return image_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta = np.random.beta(0.2,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = _read(f\"./mixup_img_dir/Train_5_rgb.png\")\n",
    "\n",
    "# # img = cv2.cvtColor(img * beta, cv2.COLOR_BGR2GRAY)\n",
    "# im_gray = 0.299 * img[:, :, 0] + 0.587 * img[:, :, 1] + 0.114 * img[:, :, 2]\n",
    "# pil_image=Image.fromarray(np.uint8(im_gray))\n",
    "# pil_image.save(f\"./mixup_img_dir/Train_5_grayscale.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscaled(x):\n",
    "    img = _read(f\"./mixup_img_dir2/{x}.png\")\n",
    "    img = 0.299 * img[:, :, 0] + 0.587 * img[:, :, 1] + 0.114 * img[:, :, 2]\n",
    "    pil_image=Image.fromarray(np.uint8(img))\n",
    "    pil_image.save(f\"./mixup_img_dir/{x}.png\")\n",
    "#     cv2.imwrite(f\"./mixup_img_dir/{x}.png\",img)\n",
    "#     resize_and_save_image_adhoc(\"./mixup_img_dir/\",img,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process,Pool \n",
    "with Pool() as p:\n",
    "        _Y_trains  =p.map(func=grayscaled, iterable=X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.util import slack_notify as slack_notify\n",
    "# slack_notify(\"変換完了\",SLACK_NOTIFY_ME)\n",
    "SLACK_NOTIFY_ME=\"https://hooks.slack.com/services/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\"\n",
    "\n",
    "import slackweb\n",
    "slack = slackweb.Slack(url=SLACK_NOTIFY_ME)\n",
    "\n",
    "slack.notify(text=\"変換完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#スラク通知\n",
    "def slack_notify(text=\"\",\n",
    "    url=SLACK_NOTIFY_ME): \n",
    "    import slackweb\n",
    "    slack = slackweb.Slack(url=url)\n",
    "    slack.notify(text=text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "def _read(path):\n",
    "    img = cv2.imread(path)    \n",
    "#     img = Image.open(path)\n",
    "#     img = np.array(img.convert(\"L\"))\n",
    "    return img\n",
    "hoge=_read(f\"./mixup_img_dir/Train_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10, 10, 10],\n",
       "        [15, 15, 15],\n",
       "        [17, 17, 17],\n",
       "        ...,\n",
       "        [ 5,  5,  5],\n",
       "        [ 3,  3,  3],\n",
       "        [ 3,  3,  3]],\n",
       "\n",
       "       [[ 5,  5,  5],\n",
       "        [ 9,  9,  9],\n",
       "        [14, 14, 14],\n",
       "        ...,\n",
       "        [ 1,  1,  1],\n",
       "        [ 1,  1,  1],\n",
       "        [ 1,  1,  1]],\n",
       "\n",
       "       [[ 7,  7,  7],\n",
       "        [ 7,  7,  7],\n",
       "        [ 7,  7,  7],\n",
       "        ...,\n",
       "        [ 1,  1,  1],\n",
       "        [ 1,  1,  1],\n",
       "        [ 3,  3,  3]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 1,  1,  1],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 1,  1,  1],\n",
       "        [ 1,  1,  1]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 1,  1,  1],\n",
       "        [ 1,  1,  1],\n",
       "        [ 0,  0,  0]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
